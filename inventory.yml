localhost:
  hosts:
    127.0.0.1:
nfs:
  hosts:
    192.168.56.7:
      ansible_user: u
      HOST_NAME: nfs
      parted:
        - dev_path: /dev/vdb
          mount_path: /exports/vdb/
          enabled: true
        - dev_path: /dev/vdc
          mount_path: /exports/vdc/
          enabled: false
      NFS_DIR: "/exports/nfs-client"
      nfs_server_exports:
        - path: /exports/vdb/
          config: /exports/vdb/ 192.168.56.0/24(rw,sync,no_root_squash,no_subtree_check)
        - path: /exports/vdc/
          config: /exports/vdc/ 192.168.56.0/24(rw,sync,no_root_squash,no_subtree_check)
          state: absent
      backup_nfs_items:
        - name: coder
          path: "/exports/nfs-client/coder-home-*"
          excludes:
            - .git
            - .venv
            - .m2
            - .vscode-server
            - node_modules
            - .cache
            - .terraform
            - .tfenv
            - .angular
            - .nvm
            - .npm
            - .local
            - .oh-my-zsh
            - go/pkg
            - "*.lock"
            - "*tmp*"
            - "Python-*"
            - "amazon-corretto-*"
xenomorph:
  hosts:
    xenomorph.tuana9a.com:
      ansible_user: root
      HOST_NAME: xenomorph
      nginx:
        conf_d: xenomorph/nginx/conf.d/
        stream_conf_d: xenomorph/nginx/stream.conf.d/
k8s_cluster_vars:
  kube_pki: &kube_pki
    - /etc/kubernetes/pki/ca.crt
    - /etc/kubernetes/pki/ca.key
    - /etc/kubernetes/pki/sa.key
    - /etc/kubernetes/pki/sa.pub
    - /etc/kubernetes/pki/front-proxy-ca.crt
    - /etc/kubernetes/pki/front-proxy-ca.key
    - /etc/kubernetes/pki/etcd/ca.crt
    - /etc/kubernetes/pki/etcd/ca.key
  kubevip: &kubevip
    inf: eth0
    vip: 192.168.56.21
k8s_cluster:
  hosts:
    # 192.168.56.22: &i-122
    #   ansible_user: u
    #   nodename: i-122
    #   vmid: 122
    #   is_control_plane: true
    #   kubesetup_completed: true
    #   kube_joined: true
    #   kube_pki: *kube_pki
    #   kubevip: *kubevip
    192.168.56.23: &i-123
      ansible_user: u
      nodename: i-123
      vmid: 123
      is_control_plane: true
      kubesetup_completed: true
      kube_joined: true
      kube_pki: *kube_pki
      kubevip: *kubevip
    # 192.168.56.24: &i-124
    #   ansible_user: u
    #   nodename: i-124
    #   vmid: 124
    #   is_control_plane: true
    #   kubesetup_completed: true
    #   kube_joined: true
    #   kube_pki: *kube_pki
    #   kubevip: *kubevip
    # 192.168.56.25: &i-125
    #   ansible_user: u
    #   nodename: i-125
    #   vmid: 125
    #   is_control_plane: true
    #   kubesetup_completed: true
    #   kube_joined: true
    #   kube_pki: *kube_pki
    #   kubevip: *kubevip
    192.168.56.31: &i-131
      ansible_user: u
      nodename: i-131
      vmid: 131
      is_control_plane: false
      kubesetup_completed: true
      kube_joined: true
    # 192.168.56.32: &i-132
    #   ansible_user: u
    #   nodename: i-132
    #   vmid: 132
    #   is_control_plane: false
    #   kubesetup_completed: true
    #   kube_joined: true
    192.168.56.33: &i-133
      ansible_user: u
      nodename: i-133
      vmid: 133
      is_control_plane: false
      kubesetup_completed: true
      kube_joined: true
    192.168.56.34: &i-134
      ansible_user: u
      nodename: i-134
      vmid: 134
      is_control_plane: false
      kubesetup_completed: true
      kube_joined: true
k8s_first_control_plane:
  hosts:
    # 192.168.56.22: *i-122
    192.168.56.23: *i-123
orisis:
  hosts:
    orisis.tuana9a.com:
      ansible_user: root
      HOST_NAME: orisis
      upstream_servers:
        - hostname: facehugger
          ip: 10.5.115.5
          http_port: 80
          https_port: 443
facehugger:
  hosts:
    192.168.56.12:
      ansible_user: u
      wireguard_client_items:
        - file: facehugger/facehugger.conf
          name: facehugger
